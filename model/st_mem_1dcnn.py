import torch
import torch.nn as nn
import torch.nn.functional as F
from functools import partial
import numpy as np

__all__ = ['ST_MEM_1DCNN_MAE', 'stmem_1dcnn_base', 'stmem_1dcnn_finetune']


# --- 1D CNN Encoder Helpers ---

class ConvBlock1D(nn.Module):
    """í‘œì¤€ 1D í•©ì„±ê³± ë¸”ë¡"""

    def __init__(self, in_channels, out_channels, kernel_size=15, stride=1, padding=7):
        super().__init__()
        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=False)
        self.bn = nn.BatchNorm1d(out_channels)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        return self.relu(self.bn(self.conv(x)))


class CNNEncoder(nn.Module):
    """MAE Pre-trainingì„ ìœ„í•œ 1D CNN ì¸ì½”ë”"""

    # [ìˆ˜ì •ëœ ë¶€ë¶„]: seq_len=2250 ì ìš©
    def __init__(self, num_leads=12, embed_dim=256, seq_len=2250,num_classes=2,**kwargs):
        super().__init__()
        self.num_classes = num_classes
        self.num_leads = num_leads
        self.embed_dim = embed_dim
        self.seq_len = seq_len

        # 1. ì´ˆê¸° ì»¨ë³¼ë£¨ì…˜: Stride 4. (2250 -> 563)
        self.input_conv = ConvBlock1D(num_leads, 64, kernel_size=32, stride=4, padding=16)

        # 2. ResNet-like ë¸”ë¡
        self.layer1 = nn.Sequential(  # Stride 4. (563 -> 141)
            ConvBlock1D(64, 128, kernel_size=15, stride=4, padding=7),
            ConvBlock1D(128, 128),
        )
        self.layer2 = nn.Sequential(  # Stride 2. (141 -> 71)
            ConvBlock1D(128, embed_dim, kernel_size=7, stride=2, padding=3),
            ConvBlock1D(embed_dim, embed_dim),
        )
        # ìµœì¢… íŠ¹ì§• ë§µ ê¸¸ì´ (L_latent): 71

        self.final_proj = nn.Conv1d(embed_dim, embed_dim, kernel_size=1)
        self.gap = nn.AdaptiveAvgPool1d(1)
        self.head = nn.Linear(embed_dim, num_classes)
        
    def forward_features(self, x):
        # x shape: [B, num_leads, 2250]
        x = self.input_conv(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.final_proj(x)
        x = self.gap(x)         # [B, embed_dim, 1]
        return x.squeeze(-1)    # [B, embed_dim] ğŸ‘ˆ íŠ¹ì§• ë²¡í„° (D_out=256)ë§Œ ë°˜í™˜
    
    # forwardë„ ìˆ˜ì •:
    def forward(self, x):
        x = self.forward_features(x)
        return self.head(x)


class CNNDecoder(nn.Module):
    """1D CNN ë””ì½”ë” (ì—­í•©ì„±ê³±/ì—…ìƒ˜í”Œë§)"""

    # [ìˆ˜ì •ëœ ë¶€ë¶„]: seq_len=2250 ì ìš©
    def __init__(self, embed_dim=256, decoder_embed_dim=128, num_leads=12, seq_len=2250):
        super().__init__()

        self.proj_up = nn.Conv1d(embed_dim, decoder_embed_dim, kernel_size=1)

        # ì—­í•©ì„±ê³±ì„ ì‚¬ìš©í•˜ì—¬ ê¸¸ì´ ë³µì› (Stride 2, 4, 4ì˜ ì—­ìˆœ)
        self.deconv_layer2 = nn.Sequential(  # Stride 2 (71 -> 142)
            nn.ConvTranspose1d(decoder_embed_dim, 128, kernel_size=7, stride=2, padding=3, output_padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
        )
        self.deconv_layer1 = nn.Sequential(  # Stride 4 (142 -> 568)
            nn.ConvTranspose1d(128, 64, kernel_size=15, stride=4, padding=7, output_padding=2),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
        )

        # ë§ˆì§€ë§‰ ê¸¸ì´ë¥¼ ì •í™•íˆ seq_len=2250ìœ¼ë¡œ ë§ì¶”ê¸°
        self.upsample = nn.Upsample(size=seq_len, mode='linear', align_corners=False)

        # ìµœì¢… ì¶œë ¥ ì±„ë„ì„ ë¦¬ë“œ ìˆ˜ë¡œ ë§ì¶”ê¸°
        self.final_conv = nn.Conv1d(64, num_leads, kernel_size=1)

    def forward(self, x):
        # x shape: [B, embed_dim, 71]
        x = self.proj_up(x)
        x = self.deconv_layer2(x)
        x = self.deconv_layer1(x)

        x = self.upsample(x)
        x = self.final_conv(x)
        # ìµœì¢… ì¶œë ¥ shape: [B, num_leads, 2250]
        return x


# --- ST_MEM 1D-CNN MAE Wrapper (ë‚˜ë¨¸ì§€ ë¡œì§ì€ seq_len=2250ì— ë§ì¶° ìë™ ì¡°ì •ë¨) ---

class ST_MEM_1DCNN_MAE(nn.Module):
    # [ìˆ˜ì •ëœ ë¶€ë¶„]: seq_len=2250 ì ìš©
    def __init__(self,
                 patch_size,
                 num_leads=12,
                 seq_len=2250,
                 embed_dim=256,
                 decoder_embed_dim=128,
                 **kwargs):
        super().__init__()

        self.num_leads = num_leads
        self.seq_len = seq_len
        self.patch_size = patch_size
        self.num_patches = seq_len // patch_size

        self.encoder = CNNEncoder(num_leads, embed_dim, seq_len)
        self.decoder = CNNDecoder(embed_dim, decoder_embed_dim, num_leads, seq_len)

        self.initialize_weights()
    # CNNì€ initializeí•„ìš” ì—†ìŒ.
    def initialize_weights(self): # <--- ì´ ë©”ì„œë“œë¥¼ ë°˜ë“œì‹œ í´ë˜ìŠ¤ ë‚´ë¶€ì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤
        pass
        
    def forward(self, series, mask_ratio=0.75):
        
        # 1. ì¸ì½”ë”© (ì „ì²´ ì‹ í˜¸ ì‚¬ìš©)
        latent = self.forward_encoder(series)
        
        # 2. ë””ì½”ë”© (ì „ì²´ íŠ¹ì§• ë§µ ì‚¬ìš©)
        pred = self.forward_decoder(latent)
        
        # 3. ì†ì‹¤ ê³„ì‚°ì„ ìœ„í•œ ë§ˆìŠ¤í¬ ìƒì„±
        mask = self.mask_and_get_indices(series, mask_ratio)
        
        # 4. ì†ì‹¤ ê³„ì‚°
        recon_loss = self.forward_loss(series, pred, mask)
        
        # main_pretrain.pyê°€ ìš”êµ¬í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
        return {"loss": recon_loss, "pred": pred, "mask": mask}
        
    def forward_encoder(self, series):
        """1D CNNì€ ë§ˆìŠ¤í‚¹ë˜ì§€ ì•Šì€ ì…ë ¥ë§Œ ë°›ëŠ” êµ¬ì¡°ê°€ ì•„ë‹ˆë¯€ë¡œ, ì „ì²´ ì‹ í˜¸ë¥¼ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
        # CNNEncoder ì¸ìŠ¤í„´ìŠ¤ (self.encoder)ì˜ forwardë¥¼ í˜¸ì¶œ
        latent = self.encoder(series) # [B, embed_dim, L_latent]
        return latent
        
    def forward_decoder(self, latent):
        """ì „ì²´ ì ì¬ ì½”ë“œë¥¼ ë””ì½”ë”ì— ì „ë‹¬í•˜ì—¬ ë³µì›í•©ë‹ˆë‹¤."""
        # CNN ë””ì½”ë” ì¸ìŠ¤í„´ìŠ¤ (self.decoder)ì˜ forwardë¥¼ í˜¸ì¶œ
        pred = self.decoder(latent) # [B, num_leads, seq_len]
        return pred
    def mask_and_get_indices(self, series, mask_ratio):
        """
        1D ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¸”ë¡ ë‹¨ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•  ì¸ë±ìŠ¤ë¥¼ ê²°ì •í•˜ê³  ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        Loss ê³„ì‚°ì„ ìœ„í•´ [B, L_patch] ì°¨ì›ì˜ maskë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        series shape: [B, C, L]
        """
        B, C, L = series.shape
        L_patch = self.num_patches
        
        # 1. ë§ˆìŠ¤í‚¹ ë¹„ìœ¨ì— ë”°ë¼ ì œê±°í•  ë¸”ë¡ ìˆ˜ ê²°ì •
        num_mask = int(mask_ratio * L_patch)
        
        # 2. ë§ˆìŠ¤í‚¹ ìœ„ì¹˜ ê²°ì • (L_patch ê¸¸ì´ì˜ ì‹œí€€ìŠ¤ì—ì„œ)
        noise = torch.rand(B, L_patch, device=series.device)
        ids_shuffle = torch.argsort(noise, dim=1)
        ids_restore = torch.argsort(ids_shuffle, dim=1) # ì›ë³¸ ìœ„ì¹˜ë¡œ ë³µì› ì¸ë±ìŠ¤
        
        # 3. ë§ˆìŠ¤í¬ ìƒì„± (1: ì†ì‹¤ ê³„ì‚°, 0: ì†ì‹¤ ê³„ì‚° ì œì™¸)
        mask = torch.zeros([B, L_patch], device=series.device)
        # ë§ˆìŠ¤í‚¹í•  ë¶€ë¶„(num_mask ê°œ)ì„ 1ë¡œ ì„¤ì •í•˜ì—¬ ì†ì‹¤ ê³„ì‚°ì— í¬í•¨
        mask[:, :num_mask] = 1.
        
        # 4. ë§ˆìŠ¤í¬ë¥¼ ì›ë˜ ì‹œê°„ì  ìœ„ì¹˜ë¡œ ì¬ë°°ì—´
        mask = torch.gather(mask, dim=1, index=ids_restore)

        return mask # [B, L_patch] í˜•íƒœ
        
    def forward_loss(self, series, pred, mask):
        """LossëŠ” ë§ˆìŠ¤í‚¹ëœ ë¶€ë¶„ì— ëŒ€í•´ì„œë§Œ MSEë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        
        # 1. ì‹ í˜¸ë¥¼ ë§ˆìŠ¤í‚¹ ë¸”ë¡ìœ¼ë¡œ ë¶„í•  (Patchify)
        # target, pred_blocks shape: [B, L_patch, C * patch_size]
        
        # Target: [B, C, L] -> [B, C, L_patch, patch_size] -> [B, L_patch, C*patch_size]
        target = series.unfold(2, self.patch_size, self.patch_size).permute(0, 2, 1, 3).contiguous()
        pred_blocks = pred.unfold(2, self.patch_size, self.patch_size).permute(0, 2, 1, 3).contiguous()
        
        target = target.view(target.shape[0], target.shape[1], -1) 
        pred_blocks = pred_blocks.view(pred_blocks.shape[0], pred_blocks.shape[1], -1)

        # 2. ë§ˆìŠ¤í¬ í™•ì¥: [B, L_patch] -> [B, L_patch, C*patch_size]
        # Loss ê³„ì‚°ì„ ìœ„í•´ ë§ˆìŠ¤í¬ë¥¼ ì‹œê·¸ë„ ì°¨ì›ê¹Œì§€ í™•ì¥í•©ë‹ˆë‹¤.
        mask = mask.unsqueeze(-1).expand_as(target)
        
        # 3. ë§ˆìŠ¤í‚¹ëœ ë¸”ë¡ì— ëŒ€í•´ì„œë§Œ MSE ê³„ì‚°
        loss = (pred_blocks - target) ** 2
        loss = loss * mask # ë§ˆìŠ¤í‚¹ëœ ë¶€ë¶„(1)ì˜ ì†ì‹¤ë§Œ ë‚¨ê¹€
        
        # 4. í‰ê·  ì†ì‹¤ ê³„ì‚° (ë§ˆìŠ¤í‚¹ëœ ë¶€ë¶„ì˜ ê°œìˆ˜ë¡œ ë‚˜ëˆ”)
        recon_loss = loss.sum() / mask.sum() 
        return recon_loss
    
def stmem_1dcnn_base(**kwargs):
    """YAML ì„¤ì •ì—ì„œ í˜¸ì¶œë˜ëŠ” ê¸°ë³¸ 1D CNN MAE ëª¨ë¸"""
    model = ST_MEM_1DCNN_MAE(**kwargs)
    return model


def stmem_1dcnn_finetune(**kwargs):
    """Fine-tuning ì‹œ Encoderë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë”ë¯¸ í•¨ìˆ˜ ì¶”ê°€"""
    model = CNNEncoder(**kwargs)
    return model

# ì´ íŒŒì¼ì´ models/__init__.py ë“±ì—ì„œ ì„í¬íŠ¸ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.